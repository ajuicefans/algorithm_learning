# 0.2 算法为什么会超时？

代码随想录 讲解网址：[算法为什么会超时？](https://www.programmercarl.com/%E5%89%8D%E5%BA%8F/On%E7%9A%84%E7%AE%97%E6%B3%95%E5%B1%85%E7%84%B6%E8%B6%85%E6%97%B6%E4%BA%86%EF%BC%8C%E6%AD%A4%E6%97%B6%E7%9A%84n%E7%A9%B6%E7%AB%9F%E6%98%AF%E5%A4%9A%E5%A4%A7%EF%BC%9F.html)

---

## LeetCode为什么会超时？

程序运行的时间超过了规定的时间，一般OJ（online judge）的超时时间就是1s

如果写出了一个$O(n)$的算法 ，其实可以估算出来n是多大的时候算法的执行时间就会超过1s了。

如果n的规模已经足够让$O(n)$的算法运行时间超过了1s，就应该考虑log(n)的解法了

---



## 从硬件配置看计算机的性能

2.7 GHz 奔腾双核，i5处理器

1Hz = 1/s，1Hz 是CPU的一次脉冲（可以理解为一次改变状态，也叫时钟周期）

- 1GHz（兆赫）= 1000MHz（兆赫）
- 1MHz（兆赫）= 1百万赫兹

所以 1GHz = 10亿Hz，表示CPU可以一秒脉冲10亿次（有10亿个时钟周期），这里不要简单理解一个时钟周期就是一次CPU运算。

例如1 + 2 = 3，cpu要执行四次才能完整这个操作

- 步骤一：把1放入寄存机，步骤二：把2放入寄存器，步骤三：做加法，步骤四：保存3。

而且计算机的cpu也不会只运行我们自己写的程序上，**同时cpu也要执行计算机的各种进程任务等等**，我们的程序仅仅是其中的一个进程而已



## 做个测试实验

在写测试程序测1s内处理多大数量级数据的时候，有三点需要注意：

- CPU执行每条指令所需的时间实际上并不相同，例如CPU执行加法和乘法操作的耗时实际上都是不一样的。
- 现在大多计算机系统的内存管理都有缓存技术，所以频繁访问相同地址的数据和访问不相邻元素所需的时间也是不同的。
- 计算机同时运行多个程序，每个程序里还有不同的进程线程在抢占资源。

尽管有很多因素影响，但是还是可以对自己程序的运行时间有一个大体的评估的。



引用算法4里面的一段话：

- 火箭科学家需要大致知道一枚试射火箭的着陆点是在大海里还是在城市中；
- 医学研究者需要知道一次药物测试是会杀死还是会治愈实验对象；

所以**任何开发计算机程序员的软件工程师都应该能够估计这个程序的运行时间是一秒钟还是一年**。

这个是最基本的，所以以上误差就不算事了。



实现三个函数，时间复杂度分别是 $O(n)$ , $O(n^2)$, $O(n\log n)$，使用加法运算来统一测试。

```cpp
// O(n)
void function1(long long n) {
    long long k = 0;
    for (long long i = 0; i < n; i++) {
        k++;
    }
}
```

```cpp
// O(n^2)
void function2(long long n) {
    long long k = 0;
    for (long long i = 0; i < n; i++) {
        for (long j = 0; j < n; j++) {
            k++;
        }
    }

}
```

```cpp
// O(nlogn)
void function3(long long n) {
    long long k = 0;
    for (long long i = 0; i < n; i++) {
        for (long long j = 1; j < n; j = j*2) { // 注意这里j=1
            k++;
        }
    }
}
```

来看一下这三个函数随着n的规模变化，耗时会产生多大的变化，先测function1 ，就把 function2 和 function3 注释掉

```cpp
int main() {
    long long n; // 数据规模
    while (1) {
        cout << "输入n：";
        cin >> n;
        milliseconds start_time = duration_cast<milliseconds >(
            system_clock::now().time_since_epoch()
        );
        function1(n);
//        function2(n);
//        function3(n);
        milliseconds end_time = duration_cast<milliseconds >(
            system_clock::now().time_since_epoch()
        );
        cout << "耗时:" << milliseconds(end_time).count() - milliseconds(start_time).count()
            <<" ms"<< endl;
    }
}
```

![程序超时2](https://code-thinking-1253855093.file.myqcloud.com/pics/20200729200018460-20230310124315093.png)

O(n)的算法，1s内大概计算机可以运行 5 * (10^ 8)次计算，可以推测一下$O(n^2)$ 的算法应该1s可以处理的数量级的规模是 5 * (10^8)开根号，实验数据如下。

![程序超时3](https://code-thinking-1253855093.file.myqcloud.com/pics/2020072919590970-20230310124318532.png)

O(n^2)的算法，1s内大概计算机可以运行 22500次计算

在推测一下$O(n\log n)$的话， 1s可以处理的数据规模是什么呢？

理论上应该是比 $O(n)$少一个数量级，因为$\log n$的复杂度 其实是很快，看一下实验数据。

![程序超时4](https://code-thinking-1253855093.file.myqcloud.com/pics/20200729195729407-20230310124322232.png)

$O(n\log n)$的算法，1s内大概计算机可以运行 2 * (10^7)次计算，符合预期。



### 实际实验的时候要考虑个人计算机的配置条件

**整体测试数据整理如下：**

<img src="https://code-thinking-1253855093.file.myqcloud.com/pics/20201208231559175-20230310124325152.png" alt="程序超时1" style="zoom:50%;" />

---



## 总结

- leetcode上做题程序为什么会有超时
- 从硬件配置上大体知道CPU的执行速度
- 测试实验看不同数量级1s内可以进行多少次运算（注意计算机硬件条件和一些代码细节）